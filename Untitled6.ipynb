{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRhvlAsGEKrmP+pJzbCISC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["DATA TOOLKIT -theory"],"metadata":{"id":"u16rXwlCIrw3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_k1JsQoqIlQh"},"outputs":[],"source":["1. What is NumPy, and why is it widely used in Python?\n","-NumPy, which stands for Numerical Python, is an essential library in the Python ecosystem, widely used for scientific computing. It provides a high-performance multidimensional array object, ndarray, and tools for working with these arrays.\n","\n","Key Features of NumPy\n","\n","N-dimensional Array Support: At its core, NumPy offers the ndarray object, enabling efficient storage and manipulation of homogeneous data types across multiple dimensions.\n","\n","Performance: NumPy operations are implemented in C, which provides a performance boost compared to pure Python implementations. This is particularly beneficial for tasks involving large datasets or complex mathematical computations.\n","\n","Comprehensive Mathematical Functions: The library includes functions for statistical analysis, linear algebra, and random number generation, among others, making it a versatile tool for data analysis and scientific research.\n","\n","Interoperability: NumPy arrays are used as the standard data container for many other libraries in the scientific Python ecosystem, facilitating data exchange and integration.\n","\n","Ease of Use: With its clear and concise syntax, NumPy is accessible to programmers from various backgrounds, simplifying the transition to scientific computing in Python.\n","\n","Practical Example: Array Operations\n","\n","Here's a simple demonstration of creating and manipulating a NumPy array:\n","\n","import numpy as np\n","\n","# Create a 2-dimensional array and perform operations\n","x = np.arange(15, dtype=np.int64).reshape(3, 5)\n","x[1:, ::2] = -99\n","print(x)\n","# Output:\n","# array([[ 0, 1, 2, 3, 4],\n","# [-99, 6, -99, 8, -99],\n","# [-99, 11, -99, 13, -99]])\n","\n","# Find the maximum value in each row\n","max_values = x.max(axis=1)\n","print(max_values)\n","# Output: array([ 4, 8, 13])\n","Why NumPy is Faster Than Lists\n","\n","NumPy arrays are stored contiguously in memory, providing the benefit of locality of reference. This storage method, combined with the fact that operations are performed in compiled C code, results in significant performance gains over traditional Python lists.\n","\n","Open Source and Community-Driven\n","\n","NumPy is an open-source project, distributed under a BSD license, and maintained by a vibrant community on GitHub. Its open nature encourages collaboration and contributions, ensuring the library stays up-to-date with the latest computing architectures and paradigms.\n","\n","Conclusion\n","\n","NumPy is a cornerstone in Python's scientific computing stack, offering efficient array manipulation and a suite of mathematical tools. Its integration with other libraries and ease of use make it an indispensable resource for data scientists, researchers, and engineers alike. Whether you're performing complex numerical simulations or analyzing large datasets, NumPy provides the functionality and performance necessary to get the job done efficiently."]},{"cell_type":"markdown","source":["2. How does broadcasting work in NumPy?\n","-Broadcasting in NumPy is a powerful feature that allows operations on arrays of different shapes without explicitly reshaping or replicating data. It simplifies mathematical operations by automatically expanding smaller arrays to match the shape of larger ones, following specific rules.\n","\n","How Broadcasting Works\n","When performing operations on two arrays, NumPy compares their shapes element-wise. It applies the following rules to determine compatibility:\n","\n","Rule 1: Matching Dimensions\n","If the dimensions of the two arrays are the same, they are compatible.\n","\n","Rule 2: Size of 1\n","If one of the dimensions is 1, it can be stretched (broadcasted) to match the other dimension.\n","\n","Rule 3: Incompatible Shapes\n","If the dimensions do not match and neither is 1, broadcasting is not possible, and a ValueError is raised.\n","\n","Examples\n","1. Scalar and Array\n","A scalar can be broadcasted to any array:\n","\n","\n","import numpy as np\n","\n","arr = np.array([1, 2, 3])\n","result = arr + 5  # Scalar 5 is broadcasted\n","print(result)  # Output: [6 7 8]\n","2. Arrays with Different Shapes\n","\n","arr1 = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n","arr2 = np.array([10, 20, 30])            # Shape: (3,)\n","result = arr1 + arr2  # arr2 is broadcasted to shape (2, 3)\n","print(result)\n","# Output:\n","# [[11 22 33]\n","#  [14 25 36]]\n","3. Higher Dimensions\n","\n","arr1 = np.array([1, 2, 3])               # Shape: (3,)\n","arr2 = np.array([[10], [20], [30]])      # Shape: (3, 1)\n","result = arr1 + arr2  # arr1 is broadcasted to shape (3, 3)\n","print(result)\n","# Output:\n","# [[11 12 13]\n","#  [21 22 23]\n","#  [31 32 33]]\n","Key Points\n","Broadcasting avoids memory overhead by not creating large intermediate arrays.\n","It works only when the shapes are compatible according to the rules.\n","If shapes are incompatible, you’ll get a ValueError.\n","This feature is particularly useful in scientific computing, where operations on multi-dimensional data are common."],"metadata":{"id":"yzqI62bNJknM"}},{"cell_type":"markdown","source":["3. What is a Pandas DataFrame?\n","-A Pandas DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It is one of the primary data structures in pandas.\n","\n","Creating a DataFrame\n","\n","You can create a DataFrame using various methods such as from a dictionary, list, or even from a CSV file.\n","\n","Example: Creating DataFrame from Dictionary\n","\n","import pandas as pd\n","\n","data = {\n","\"Name\": [\"Tom\", \"Nick\", \"Krish\", \"Jack\"],\n","\"Age\": [20, 21, 19, 18]\n","}\n","\n","df = pd.DataFrame(data)\n","print(df)\n","Output:\n","\n","Name Age\n","0 Tom 20\n","1 Nick 21\n","2 Krish 19\n","3 Jack 18\n","Accessing Data\n","\n","You can access data in a DataFrame using various methods like loc[] and iloc[].\n","\n","Example: Using loc[] to Access Rows by Label\n","\n","import pandas as pd\n","\n","data = {\n","\"calories\": [420, 380, 390],\n","\"duration\": [50, 40, 45]\n","}\n","\n","df = pd.DataFrame(data, index=[\"day1\", \"day2\", \"day3\"])\n","print(df.loc[\"day2\"])\n","Output:\n","\n","calories 380\n","duration 40\n","Name: day2, dtype: int64\n","Handling Missing Data\n","\n","Pandas provides functions like isnull(), fillna(), and dropna() to handle missing data.\n","\n","Example: Filling Missing Values\n","\n","import pandas as pd\n","import numpy as np\n","\n","data = {\n","'First Score': [100, 90, np.nan, 95],\n","'Second Score': [30, np.nan, 45, 56],\n","'Third Score': [52, 40, 80, 98]\n","}\n","\n","df = pd.DataFrame(data)\n","df_filled = df.fillna(0)\n","print(df_filled)\n","Output:\n","\n","First Score Second Score Third Score\n","0 100.0 30.0 52.0\n","1 90.0 0.0 40.0\n","2 0.0 45.0 80.0\n","3 95.0 56.0 98.0\n","Pandas DataFrames are versatile and powerful for data manipulation and analysis."],"metadata":{"id":"CP_WPpTdJ7b6"}},{"cell_type":"markdown","source":["4. Explain the use of the groupby() method in Pandas?\n","-The groupby method in Pandas is a powerful tool for grouping data and performing operations on those groups. It is commonly used for data aggregation, transformation, and analysis. Here's a concise explanation of its use:\n","\n","What does groupby do?\n","The groupby method splits the data into groups based on some criteria (e.g., a column or multiple columns), applies a function to each group, and then combines the results into a new DataFrame or Series.\n","\n","Key Steps in groupby:\n","Splitting: Divide the data into groups based on values in one or more columns.\n","Applying: Perform an operation (e.g., aggregation, transformation, or filtering) on each group.\n","Combining: Merge the results into a new structure.\n","Common Use Cases:\n","Aggregation: Summarize data using functions like sum(), mean(), count(), etc.\n","Transformation: Modify data within each group (e.g., normalize values).\n","Filtering: Select groups that meet specific criteria.\n","Example 1: Aggregation\n","\n","import pandas as pd\n","\n","# Sample DataFrame\n","data = {'Category': ['A', 'B', 'A', 'B', 'A'],\n","        'Values': [10, 20, 30, 40, 50]}\n","df = pd.DataFrame(data)\n","\n","# Group by 'Category' and calculate the sum of 'Values'\n","result = df.groupby('Category')['Values'].sum()\n","print(result)\n","Output:\n","\n","\n","Category\n","A    90\n","B    60\n","Name: Values, dtype: int64\n","Example 2: Multiple Aggregations\n","\n","# Group by 'Category' and calculate multiple aggregations\n","result = df.groupby('Category')['Values'].agg(['sum', 'mean', 'count'])\n","print(result)\n","Output:\n","\n","\n","          sum  mean  count\n","Category                    \n","A          90  30.0      3\n","B          60  30.0      2\n","Example 3: Transformation\n","\n","# Normalize 'Values' within each group\n","df['Normalized'] = df.groupby('Category')['Values'].transform(lambda x: x / x.sum())\n","print(df)\n","Output:\n","\n","\n","  Category  Values  Normalized\n","0        A      10    0.111111\n","1        B      20    0.333333\n","2        A      30    0.333333\n","3        B      40    0.666667\n","4        A      50    0.555556\n","Key Parameters of groupby:\n","by: Column(s) or keys to group by.\n","axis: Whether to group rows (axis=0, default) or columns (axis=1).\n","level: Group by a specific level in a MultiIndex.\n","The groupby method is highly versatile and can be combined with other Pandas functions to perform complex data manipulations efficiently."],"metadata":{"id":"26G_VNc5KKH_"}},{"cell_type":"markdown","source":["5. Why is Seaborn preferred for statistical visualizations?\n","-Seaborn is a Python library that provides a high-level interface for creating attractive and informative statistical graphics. It is built on top of matplotlib and integrates closely with pandas data structures, making it an essential tool for data analysis and visualization.\n","\n","Creating Visualizations with Seaborn\n","\n","Seaborn simplifies the process of creating visualizations by providing a dataset-oriented API. This means you can focus on the meaning of your data and the story you want to tell, rather than the mechanics of plotting. Here's an example of how you can create a visualization with Seaborn:\n","\n","import seaborn as sns\n","import pandas as pd\n","\n","# Load an example dataset\n","tips = sns.load_dataset(\"tips\")\n","\n","# Create a visualization\n","sns.relplot(\n","data=tips,\n","x=\"total_bill\",\n","y=\"tip\",\n","col=\"time\",\n","hue=\"smoker\",\n","style=\"smoker\",\n","size=\"size\",\n",")\n","In this example, Seaborn automatically handles the details of creating a relational plot, including the mapping of dataframe columns to visual attributes like color and size.\n","\n","Statistical Estimation and Plot Types\n","\n","Seaborn excels at statistical estimation and offers a variety of plot types to represent data distributions and relationships. Some of the plot types available in Seaborn include:\n","\n","Line plots: Useful for visualizing relationships involving time or ordered categories.\n","\n","Scatter plots: Ideal for showing the relationship between two continuous variables.\n","\n","Box plots: Provide a visual summary of the distribution of a dataset, highlighting the median, quartiles, and outliers.\n","\n","Violin plots: Similar to box plots but include a kernel density estimation to show the distribution shape.\n","\n","Bar plots: Represent an estimate of central tendency for a numeric variable with error bars to indicate uncertainty.\n","\n","Count plots: Show the counts of observations in each categorical bin using bars.\n","\n","KDE plots: Visualize the probability density of a continuous variable.\n","\n","Customization and Flexibility\n","\n","Seaborn offers a balance between ease of use and customization. It comes with opinionated defaults that create presentable plots with minimal effort. However, it also allows for extensive customization to fine-tune your visualizations for publication quality. You can adjust the plot's theme, scale, color palette, and more to fit the context of your presentation or publication.\n","\n","Integration with Pandas\n","\n","Seaborn's integration with pandas makes it straightforward to work with dataframes. You can pass pandas dataframes directly to Seaborn's plotting functions, and it will internally perform the necessary semantic mapping and statistical aggregation. This integration streamlines the visualization process, especially when working with complex datasets.\n","\n","Example of Seaborn with Pandas\n","\n","Here's an example of how you can use Seaborn together with pandas to create a box plot:\n","\n","import seaborn as sns\n","import pandas as pd\n","\n","# Load data from a CSV file\n","data = pd.read_csv(\"nba.csv\")\n","\n","# Create a box plot\n","sns.boxplot(data['Age'], data['Weight'])\n","This example demonstrates the simplicity of creating a box plot with Seaborn, where 'Age' and 'Weight' are columns in the 'nba.csv' dataframe.\n","\n","Conclusion\n","\n","Seaborn is a powerful tool for data visualization in Python. It simplifies the creation of complex statistical graphics, allowing you to convey insights effectively. Whether you're exploring data interactively or preparing a final presentation, Seaborn's high-level interface and integration with pandas make it an indispensable library for data analysts and scientists."],"metadata":{"id":"CcWSwyauKaSr"}},{"cell_type":"markdown","source":["6. What are the differences between NumPy arrays and Python lists?\n","-1. Performance\n","NumPy Arrays: Faster due to their implementation in C and optimized for numerical computations.\n","Python Lists: Slower as they are general-purpose containers and not optimized for numerical operations.\n","2. Data Type\n","NumPy Arrays: Homogeneous; all elements must be of the same data type (e.g., integers, floats).\n","Python Lists: Heterogeneous; can store elements of different data types (e.g., integers, strings, objects).\n","3. Memory Efficiency\n","NumPy Arrays: More memory-efficient because they store data in contiguous blocks of memory.\n","Python Lists: Less memory-efficient as they store references to objects, which can lead to overhead.\n","4. Functionality\n","NumPy Arrays: Provide a wide range of mathematical, statistical, and linear algebra operations directly.\n","Python Lists: Limited built-in operations; require loops or external libraries for numerical computations.\n","5. Indexing and Slicing\n","NumPy Arrays: Support advanced slicing, broadcasting, and multidimensional indexing.\n","Python Lists: Support basic slicing but lack advanced features like broadcasting.\n","6. Mutability\n","NumPy Arrays: Mutable; elements can be changed, but resizing is less flexible.\n","Python Lists: Mutable and can be resized dynamically (e.g., appending or removing elements).\n","7. Use Case\n","NumPy Arrays: Ideal for scientific computing, data analysis, and large-scale numerical operations.\n","Python Lists: Better suited for general-purpose programming and small-scale tasks.\n","In summary, NumPy arrays are specialized for numerical and scientific tasks, while Python lists are versatile and better for general use."],"metadata":{"id":"YUUfPkzgKvdX"}},{"cell_type":"markdown","source":[],"metadata":{"id":"lDlRzX4IL6iY"}},{"cell_type":"markdown","source":["7. What is a heatmap, and when should it be used?\n","-A heatmap is a graphical representation of data where individual values are represented as colors. It is particularly useful for visualizing matrix data, where the color intensity represents the magnitude of the values.\n","\n","Using Seaborn to Create a Heatmap\n","\n","Seaborn is a powerful Python library for data visualization based on Matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. The seaborn.heatmap() function is used to create heatmaps.\n","\n","Basic Heatmap\n","\n","To create a basic heatmap, you need a 2D dataset. Here is an example using random data:\n","\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Generate random data\n","data = np.random.randint(low=1, high=100, size=(10, 10))\n","\n","# Create a heatmap\n","sns.heatmap(data)\n","plt.show()\n","Customizing the Heatmap\n","\n","You can customize various aspects of the heatmap, such as the colormap, annotations, and colorbar.\n","\n","Colormap\n","\n","You can change the colormap using the cmap parameter:\n","\n","sns.heatmap(data, cmap=\"YlGnBu\")\n","plt.show()\n","Annotations\n","\n","To display the data values in each cell, use the annot parameter:\n","\n","sns.heatmap(data, annot=True, fmt=\"d\")\n","plt.show()\n","Colorbar\n","\n","You can hide the colorbar by setting the cbar parameter to False:\n","\n","sns.heatmap(data, cbar=False)\n","plt.show()\n","Using Plotly to Create a Heatmap\n","\n","Plotly is another powerful library for creating interactive visualizations. The plotly.express.imshow() function can be used to create heatmaps.\n","\n","Basic Heatmap\n","\n","Here is an example of creating a basic heatmap using Plotly:\n","\n","import plotly.express as px\n","\n","# Generate random data\n","data = np.random.randint(low=1, high=100, size=(10, 10))\n","\n","# Create a heatmap\n","fig = px.imshow(data)\n","fig.show()\n","Customizing the Heatmap\n","\n","You can customize the heatmap by adding text annotations and adjusting the aspect ratio.\n","\n","Text Annotations\n","\n","To add text annotations, use the text_auto parameter:\n","\n","fig = px.imshow(data, text_auto=True)\n","fig.show()\n","Aspect Ratio\n","\n","To adjust the aspect ratio, use the aspect parameter:\n","\n","fig = px.imshow(data, aspect=\"auto\")\n","fig.show()\n","Conclusion\n","\n","Heatmaps are a versatile tool for visualizing matrix data. Both Seaborn and Plotly provide powerful functions to create and customize heatmaps. Seaborn is great for static visualizations, while Plotly offers interactive capabilities\n","1\n","2\n","3\n",". Choose the library that best fits your needs and start visualizing your data effectively."],"metadata":{"id":"5kbbquTsMhqx"}},{"cell_type":"markdown","source":["8. What does the term “vectorized operation” mean in NumPy?\n","-In NumPy, a vectorized operation refers to performing element-wise computations directly on entire arrays without using explicit loops. This makes NumPy operations significantly faster and more efficient than traditional Python loops because they utilize optimized low-level implementations.\n","\n","For example, instead of looping through arrays to perform operations, NumPy allows you to apply operations directly:\n","\n","python\n","import numpy as np\n","\n","# Creating NumPy arrays\n","a = np.array([1, 2, 3])\n","b = np.array([4, 5, 6])\n","\n","# Vectorized addition\n","c = a + b  # No need for explicit looping\n","\n","print(c)  # Output: [5 7 9]\n","Since NumPy operations are highly optimized, they run much faster than equivalent loop-based implementations. This is one of the reasons NumPy is widely used in scientific computing and machine learning."],"metadata":{"id":"BTSRuxtjNAeq"}},{"cell_type":"markdown","source":["9. How does Matplotlib differ from Plotly?\n","- Matplotlib and Plotly are both powerful visualization libraries in Python, but they have distinct features and use cases.\n","\n","Key Differences\n","Interactivity:\n","\n","Matplotlib: Primarily used for static plots. While it has some interactivity via plt.show(), it is not as dynamic as Plotly.\n","\n","Plotly: Designed for interactive plots with features like hover effects, zooming, and clickable elements. Ideal for web-based applications and dashboards.\n","\n","Ease of Use:\n","\n","Matplotlib: Requires more manual formatting but gives deep control over plot elements. Often used in scientific computing and academic research.\n","\n","Plotly: More user-friendly with built-in themes and automatic styling.\n","Customization:\n","\n","Matplotlib: Offers fine-grained control but requires additional work for complex customizations.\n","\n","Plotly: Provides automatic layouts and formatting, making complex visualizations easier.\n","\n","Performance & Data Handling:\n","\n","Matplotlib: Works well for static and simple visualizations; can be slow with large datasets.\n","\n","Plotly: Optimized for larger datasets and web-based applications; integrates well with Dash for dashboards.\n","\n","Use Cases:\n","\n","Matplotlib: Best for academic plots, research papers, and non-interactive visualizations.\n","Plotly: Great for data dashboards, web apps, and interactive presentations."],"metadata":{"id":"MDSHme7aNwmG"}},{"cell_type":"markdown","source":["10. What is the significance of hierarchical indexing in Pandas?\n","-Hierarchical indexing, also known as multi-level indexing, is a powerful feature in Pandas that allows you to work with data in a multi-dimensional way within a two-dimensional DataFrame or Series. It provides a way to handle and analyze data with multiple levels of indexing, making it easier to organize, filter, and manipulate complex datasets.\n","\n","Significance of Hierarchical Indexing in Pandas\n","Organizing Complex Data:\n","\n","Hierarchical indexing allows you to represent data with multiple dimensions (e.g., rows and columns) in a compact and structured way.\n","For example, you can group data by categories and subcategories, making it easier to analyze relationships between them.\n","Efficient Data Selection:\n","\n","It enables you to perform slicing and subsetting operations on multiple levels of the index.\n","You can access specific rows or columns using tuples or by specifying levels, which simplifies working with large datasets.\n","Facilitates Grouping and Aggregation:\n","\n","Hierarchical indexing works seamlessly with grouping operations (groupby) and allows for easy aggregation of data at different levels.\n","For example, you can calculate statistics for each group or subgroup in a dataset.\n","Improved Data Representation:\n","\n","It makes the data more readable and intuitive by organizing it hierarchically.\n","For example, sales data can be indexed by region, then by city, and then by product category.\n","Flexibility in Reshaping Data:\n","\n","Hierarchical indexing is essential for reshaping operations like stack() and unstack(), which allow you to pivot data between wide and long formats.\n","This is particularly useful for preparing data for visualization or analysis.\n","Handling Missing Data:\n","\n","It provides better control over missing data by allowing you to align data at multiple levels of the index.\n","Example of Hierarchical Indexing\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Creating a DataFrame with hierarchical indexing\n","data = pd.DataFrame(\n","    np.random.randn(6, 2),\n","    index=[['Region1', 'Region1', 'Region2', 'Region2', 'Region3', 'Region3'],\n","           ['CityA', 'CityB', 'CityA', 'CityB', 'CityA', 'CityB']],\n","    columns=['Metric1', 'Metric2']\n",")\n","\n","# Setting hierarchical index\n","data.index.names = ['Region', 'City']\n","\n","print(data)\n","Output:\n","\n","\n","                 Metric1   Metric2\n","Region  City                     \n","Region1 CityA  0.123456  1.234567\n","        CityB -0.987654  0.876543\n","Region2 CityA  0.456789 -1.234567\n","        CityB -0.654321  0.543210\n","Region3 CityA  1.111111 -0.222222\n","        CityB -0.333333  0.444444\n","Key Operations:\n","Accessing Data: data.loc['Region1'] or data.loc[('Region1', 'CityA')]\n","Slicing: data.loc['Region1':'Region2']\n","Unstacking: data.unstack(level='City')\n","Stacking: data.stack()\n","Hierarchical indexing is a cornerstone of Pandas' flexibility, enabling you to work with complex datasets in a clean and efficient manner."],"metadata":{"id":"WGSvUFBUOclu"}},{"cell_type":"markdown","source":["11. What is the role of Seaborn’s pairplot() function?\n","-Pair plots are a powerful tool for visualizing the relationships between multiple variables in a dataset. In Python, the Seaborn library provides a convenient function pairplot to create a grid of scatter plots that compare each variable in your dataset against all others. Additionally, it generates histograms or Kernel Density Estimates (KDEs) along the diagonal to show the distribution of each variable.\n","\n","Code Example\n","\n","Here's a basic example of how to use pairplot in Seaborn:\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Load an example dataset\n","penguins = sns.load_dataset(\"penguins\")\n","\n","# Create a pair plot\n","sns.pairplot(penguins)\n","\n","# Display the plot\n","plt.show()\n","Customization and Additional Features\n","\n","The pairplot function is highly customizable. You can color the points using a categorical variable with the hue parameter, change the kind of plot for both the grid and the diagonal with kind and diag_kind, and control the size and aspect ratio of each subplot with height and aspect.\n","\n","For example, to create a pair plot with different markers for each species in the penguins dataset, you could do the following:\n","\n","sns.pairplot(penguins, hue=\"species\", markers=[\"o\", \"s\", \"D\"])\n","If you want to focus on specific variables, use the vars, x_vars, and y_vars parameters to select them. To create a corner plot, which only includes the lower triangle of the grid, set corner=True.\n","\n","Advanced Customization\n","\n","For more advanced customization, pairplot returns a PairGrid object, which can be further modified. For instance, you can map additional functions to different parts of the grid to overlay different kinds of plots:\n","\n","g = sns.pairplot(penguins, diag_kind=\"kde\")\n","g.map_lower(sns.kdeplot, levels=4, color=\".2\")\n","This will add contour lines to the lower triangle of the grid, enhancing the visual representation of density.\n","\n","Considerations\n","\n","When using pairplot, it's important to note that it can be computationally intensive for large datasets. Additionally, if your dataset contains non-numeric variables, you should explicitly specify which variables to include, or they will be ignored.\n","\n","Seaborn's pairplot is a high-level interface for PairGrid. If you require more flexibility than pairplot provides, consider using PairGrid directly. This allows for more granular control over the types of plots displayed and their properties.\n","\n","In summary, pairplot is a versatile function that can quickly give you a comprehensive overview of the pairwise relationships within your dataset, with the flexibility to tailor the output to your specific analysis needs."],"metadata":{"id":"fvkinMKDOwk0"}},{"cell_type":"markdown","source":["12. What is the purpose of the describe() function in Pandas?\n","-Pandas is a powerful and flexible open-source data analysis and manipulation library for Python. It provides data structures and functions needed to work with structured data seamlessly. The primary data structures in Pandas are Series and DataFrame.\n","\n","Key Features of Pandas\n","\n","Data Structures\n","\n","Series: A one-dimensional labeled array capable of holding any data type.\n","\n","DataFrame: A two-dimensional labeled data structure with columns of potentially different types. It is similar to a table in a database or an Excel spreadsheet.\n","\n","DataFrame.describe() Method\n","\n","The describe() method in Pandas is used to generate descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution, excluding NaN values\n","1\n","2\n",".\n","\n","Syntax\n","\n","DataFrame.describe(percentiles=None, include=None, exclude=None)\n","Parameters\n","\n","percentiles: List-like of numbers between 0 and 1 to include in the output. Default is [.25, .5, .75].\n","\n","include: List-like of dtypes or 'all' to include in the result. Default is None.\n","\n","exclude: List-like of dtypes to exclude from the result. Default is None.\n","\n","Returns\n","\n","Series or DataFrame: Summary statistics of the Series or DataFrame provided.\n","\n","Examples\n","\n","Numeric Series\n","\n","import pandas as pd\n","s = pd.Series([1, 2, 3])\n","print(s.describe())\n","Output:\n","\n","count 3.0\n","mean 2.0\n","std 1.0\n","min 1.0\n","25% 1.5\n","50% 2.0\n","75% 2.5\n","max 3.0\n","dtype: float64\n","Categorical Series\n","\n","s = pd.Series(['a', 'a', 'b', 'c'])\n","print(s.describe())\n","Output:\n","\n","count 4\n","unique 3\n","top a\n","freq 2\n","dtype: object\n","DataFrame\n","\n","df = pd.DataFrame({\n","'categorical': pd.Categorical(['d', 'e', 'f']),\n","'numeric': [1, 2, 3],\n","'object': ['a', 'b', 'c']\n","})\n","print(df.describe())\n","Output:\n","\n","numeric\n","count 3.0\n","mean 2.0\n","std 1.0\n","min 1.0\n","25% 1.5\n","50% 2.0\n","75% 2.5\n","max 3.0\n","Important Considerations\n","\n","For numeric data, the result includes count, mean, std, min, max, and percentiles.\n","\n","For object data, the result includes count, unique, top, and freq.\n","\n","The include and exclude parameters can be used to limit which columns are analyzed\n","1\n","3\n",".\n","\n","Pandas is an essential tool for data analysis in Python, offering robust data manipulation capabilities and a wide range of functionalities to handle various data types and operations efficiently."],"metadata":{"id":"ieTJoB7OPTIB"}},{"cell_type":"markdown","source":["13. Why is handling missing data important in Pandas?\n","-Missing data is a common issue in real-world datasets and can significantly impact data analysis and machine learning models. In Pandas, missing data is represented by None or NaN (Not a Number). Pandas provides several functions to detect, remove, and replace missing values.\n","\n","Detecting Missing Values\n","\n","To identify missing values in a DataFrame, you can use the isnull() and notnull() functions. These functions return a DataFrame of Boolean values indicating the presence of missing values.\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Sample DataFrame\n","data = {'First Score': [100, 90, np.nan, 95],\n","'Second Score': [30, 45, 56, np.nan],\n","'Third Score': [np.nan, 40, 80, 98]}\n","df = pd.DataFrame(data)\n","\n","# Check for missing values\n","print(df.isnull())\n","Removing Missing Values\n","\n","You can remove rows or columns with missing values using the dropna() function. This function provides flexibility to drop rows or columns based on the presence of missing values.\n","\n","# Drop rows with at least one missing value\n","df_cleaned = df.dropna()\n","print(df_cleaned)\n","\n","# Drop columns with at least one missing value\n","df_cleaned = df.dropna(axis=1)\n","print(df_cleaned)\n","Filling Missing Values\n","\n","Instead of removing missing values, you can fill them using the fillna() function. This function allows you to replace missing values with a specified value, such as the mean, median, or mode of the column.\n","\n","# Fill missing values with a specified value\n","df_filled = df.fillna(0)\n","print(df_filled)\n","\n","# Fill missing values with the mean of the column\n","df['First Score'] = df['First Score'].fillna(df['First Score'].mean())\n","print(df)\n","Interpolating Missing Values\n","\n","For numerical data, you can use the interpolate() function to estimate missing values using various interpolation methods.\n","\n","# Interpolate missing values using linear method\n","df_interpolated = df.interpolate(method='linear')\n","print(df_interpolated)\n","Replacing Missing Values\n","\n","The replace() function can be used to replace missing values with a specified value or another DataFrame.\n","\n","# Replace missing values with a specified value\n","df_replaced = df.replace(np.nan, -99)\n","print(df_replaced)\n","\n","# Replace missing values using another DataFrame\n","data2 = {'First Score': [10, 20, 30, 40],\n","'Second Score': [10, 20, 30, 40],\n","'Third Score': [10, 20, 30, 40]}\n","df2 = pd.DataFrame(data2)\n","df_filled = df.fillna(df2)\n","print(df_filled)\n","Important Considerations\n","\n","Handling missing data is crucial for accurate data analysis and modeling. Depending on the context and the nature of the data, you can choose to remove, fill, or interpolate missing values. Each method has its advantages and limitations, and the choice should be based on the specific requirements of your analysis."],"metadata":{"id":"vaJi0rakPmgZ"}},{"cell_type":"markdown","source":["14. What are the benefits of using Plotly for data visualization?\n","-Interactive data visualization allows users to explore and understand data more effectively by providing dynamic and engaging visual representations. Python offers several powerful libraries for creating interactive visualizations, including Bokeh and Plotly.\n","\n","Bokeh\n","\n","Bokeh is a Python library for creating interactive visualizations that can be rendered in web browsers using HTML and JavaScript. It is particularly useful for building web-based dashboards and applications. Here are the steps to create a visualization with Bokeh:\n","\n","Prepare the Data: Use libraries like Pandas and Numpy to handle and transform your data.\n","\n","Determine Where the Visualization Will Be Rendered: You can generate a static HTML file or render the visualization inline in a Jupyter Notebook.\n","\n","Set up the Figure: Customize the figure, including titles, tick marks, and tools for user interactions.\n","\n","Connect to and Draw Your Data: Use Bokeh's renderers to draw your data with various markers and shapes.\n","\n","Organize the Layout: Arrange multiple figures in a grid or tabbed layout.\n","\n","Preview and Save: View your visualization in a browser or notebook and save it to an image file if desired\n","1\n",".\n","\n","Here is an example of creating a simple scatter plot with Bokeh:\n","\n","from bokeh.plotting import figure, show, output_file\n","from bokeh.io import output_notebook\n","\n","# Prepare the data\n","x = [1, 2, 3, 4, 5]\n","y = [6, 7, 2, 4, 5]\n","\n","# Output to a static HTML file\n","output_file(\"scatter.html\")\n","\n","# Create a new plot\n","p = figure(title=\"Simple Scatter Plot\", x_axis_label='X', y_axis_label='Y')\n","\n","# Add a scatter renderer with circle markers\n","p.circle(x, y, size=10, color=\"navy\", alpha=0.5)\n","\n","# Show the results\n","show(p)\n","Plotly\n","\n","Plotly is another powerful library for creating interactive visualizations in Python. It offers a variety of graph types, such as line charts, scatter plots, bar charts, histograms, and more. Plotly visualizations are highly interactive, allowing users to zoom in, hover for data insights, and customize the appearance.\n","\n","To get started with Plotly, you need to install it using the following command:\n","\n","pip install plotly\n","Here is an example of creating a line chart with Plotly:\n","\n","import plotly.express as px\n","\n","# Sample data\n","df = px.data.iris()\n","\n","# Create a line chart\n","fig = px.line(df, x='sepal_width', y='sepal_length', title='Sepal Width vs Length')\n","\n","# Show the plot\n","fig.show()\n","Adding Interactivity\n","\n","Both Bokeh and Plotly provide various ways to add interactivity to your visualizations. For example, you can add hover actions, selection tools, and linked axes to enhance the user experience.\n","\n","Bokeh Example: Adding Hover Tool\n","\n","from bokeh.models import HoverTool\n","\n","# Add hover tool\n","hover = HoverTool()\n","hover.tooltips = [(\"X\", \"@x\"), (\"Y\", \"@y\")]\n","p.add_tools(hover)\n","\n","# Show the results\n","show(p)\n","Plotly Example: Adding Dropdown Menu\n","\n","import plotly.graph_objects as go\n","\n","# Create a scatter plot\n","fig = go.Figure(data=[go.Scatter(x=[1, 2, 3], y=[4, 5, 6], mode='markers')])\n","\n","# Add dropdown menu\n","fig.update_layout(\n","updatemenus=[\n","dict(\n","buttons=list([\n","dict(\n","args=[\"type\", \"scatter\"],\n","label=\"Scatter Plot\",\n","method=\"restyle\"\n","),\n","dict(\n","args=[\"type\", \"bar\"],\n","label=\"Bar Chart\",\n","method=\"restyle\"\n",")\n","]),\n","direction=\"down\"\n",")\n","]\n",")\n","\n","# Show the plot\n","fig.show()\n","By leveraging these libraries, you can create interactive and visually appealing data visualizations that help users explore and understand complex datasets."],"metadata":{"id":"UnSj0N3pP0iC"}},{"cell_type":"markdown","source":["15. How does NumPy handle multidimensional arrays?\n","-NumPy is a powerful library in Python that excels at handling multidimensional arrays, also known as ndarrays. Here's a concise overview of how it manages them:\n","\n","1. Creation of Multidimensional Arrays\n","NumPy allows you to create arrays of any dimension using functions like numpy.array(), numpy.zeros(), numpy.ones(), and numpy.random.\n","Example:\n","import numpy as np\n","array_2d = np.array([[1, 2, 3], [4, 5, 6]])  # 2D array\n","array_3d = np.ones((2, 3, 4))  # 3D array filled with ones\n","\n","2. Efficient Storage and Operations\n","NumPy arrays are stored in contiguous memory blocks, making operations like slicing, indexing, and mathematical computations highly efficient.\n","Operations are applied element-wise, and broadcasting allows operations between arrays of different shapes.\n","3. Shape and Dimensions\n","The .shape attribute provides the dimensions of the array, while .ndim gives the number of dimensions.\n","Example:\n","print(array_2d.shape)  # Output: (2, 3)\n","print(array_2d.ndim)   # Output: 2\n","\n","4. Indexing and Slicing\n","You can access elements using indices, and slicing works seamlessly across multiple dimensions.\n","Example:\n","print(array_2d[1, 2])  # Access element at row 1, column 2\n","print(array_2d[:, 1])  # Slice all rows, column 1\n","\n","5. Reshaping and Transposing\n","Arrays can be reshaped using .reshape() and transposed using .T.\n","Example:\n","reshaped = array_2d.reshape(3, 2)  # Reshape to 3x2\n","transposed = array_2d.T            # Transpose the array\n","\n","6. Broadcasting\n","NumPy supports broadcasting, allowing operations between arrays of different shapes by automatically expanding dimensions.\n","Example:\n","array = np.array([[1, 2, 3], [4, 5, 6]])\n","result = array + np.array([10, 20, 30])  # Adds row-wise\n","\n","7. Advanced Features\n","Axis Operations: Functions like sum(), mean(), etc., can operate along specific axes.\n","print(array_2d.sum(axis=0))  # Sum along columns\n","print(array_2d.sum(axis=1))  # Sum along rows\n","\n","Masking and Boolean Indexing: You can filter elements using conditions.\n","print(array_2d[array_2d > 3])  # Elements greater than 3\n","\n","Why NumPy for Multidimensional Arrays?\n","Performance: Faster than Python lists due to optimized C-based implementation.\n","Flexibility: Supports a wide range of operations, from basic arithmetic to complex linear algebra.\n","Scalability: Handles large datasets efficiently.\n","\n","NumPy's multidimensional array handling is a cornerstone of scientific computing in Python, making it indispensable for tasks like data analysis, machine learning, and numerical simulations."],"metadata":{"id":"orx2rO9ZQF8e"}},{"cell_type":"markdown","source":[" 16. What is the role of Bokeh in data visualization.\n"," -Bokeh is a powerful Python library for creating interactive visualizations that are web-friendly and scalable. Its primary role in data visualization includes:\n","\n","Key Features & Role\n","Interactive Plots – Bokeh allows users to build highly interactive visualizations with tools like zooming, panning, and hover effects.\n","\n","Web-Ready – Unlike static libraries like Matplotlib, Bokeh generates plots as JavaScript-enabled HTML documents, making it perfect for web applications.\n","\n","Scalability – It can handle large datasets efficiently and integrate with databases and streaming data sources.\n","\n","Customizable Dashboards – Bokeh works seamlessly with Flask and Django, making it great for building web-based dashboards.\n","\n","Supports Various Plot Types – From simple scatter plots to complex network graphs, Bokeh can generate dynamic visuals.\n","\n","from bokeh.plotting import figure, show\n","from bokeh.io import output_notebook\n","\n","output_notebook()  # Enables inline display in Jupyter\n","\n","# Create figure\n","p = figure(title=\"Simple Bokeh Plot\", x_axis_label=\"X\", y_axis_label=\"Y\")\n","\n","# Add line\n","p.line([1, 2, 3, 4], [10, 20, 30, 40], line_width=2)\n","\n","# Show plot\n","show(p)\n","\n","\n","This will generate an interactive plot directly in your notebook or as an HTML file."],"metadata":{"id":"uRljJgn4QU1o"}},{"cell_type":"markdown","source":["17. Explain the difference between apply() and map() in Pandas?\n","-In Pandas, both apply() and map() are used to apply functions to data, but they differ in their scope and use cases. Here's a clear breakdown:\n","\n","1. map()\n","Scope: Works only on Series (one-dimensional data).\n","Functionality: Applies a function element-wise to each value in the Series.\n","Use Case: Best for simple transformations or mappings on a single column or Series.\n","Input: Can take a function, dictionary, or Series as an argument.\n","\n","Example:\n","\n","import pandas as pd\n","\n","# Sample Series\n","s = pd.Series([1, 2, 3, 4])\n","\n","# Using map to square each element\n","result = s.map(lambda x: x**2)\n","print(result)\n","\n","\n","Output:\n","\n","0     1\n","1     4\n","2     9\n","3    16\n","dtype: int64\n","\n","2. apply()\n","Scope: Works on both Series and DataFrames (one-dimensional or two-dimensional data).\n","Functionality: Applies a function along an axis (rows or columns) for DataFrames or element-wise for Series.\n","Use Case: More versatile; used for complex operations, row/column-wise transformations, or custom logic.\n","Input: Can take any callable function.\n","\n","Example with Series:\n","\n","# Using apply to square each element in a Series\n","result = s.apply(lambda x: x**2)\n","print(result)\n","\n","\n","Example with DataFrame:\n","\n","# Sample DataFrame\n","df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n","\n","# Using apply to sum values row-wise\n","result = df.apply(lambda row: row.sum(), axis=1)\n","print(result)\n","\n","\n","Output:\n","\n","0     5\n","1     7\n","2     9\n","dtype: int64\n","\n","Key Differences:\n","Feature\tmap()\tapply()\n","Scope\tSeries only\tSeries and DataFrame\n","Axis Control\tNot applicable\tCan specify axis (rows/columns)\n","Complexity\tSimple element-wise operations\tComplex row/column-wise operations\n","Input\tFunction, dictionary, or Series\tCallable function only\n","\n","In summary, use map() for straightforward element-wise operations on a Series, and apply() for more flexible and complex transformations, especially when working with DataFrames."],"metadata":{"id":"fW-DqUIGRCn5"}},{"cell_type":"markdown","source":["18. What are some advanced features of NumPy?\n","-NumPy is a powerful Python library used for numerical computing, particularly with arrays. One of its essential functions is numpy.mean, which computes the arithmetic mean of array elements along a specified axis\n","1\n","2\n",".\n","\n","Definition and Usage\n","\n","The numpy.mean function calculates the average of the array elements. By default, it computes the mean of the flattened array, but you can specify an axis to compute the mean along that axis. The function signature is as follows:\n","\n","numpy.mean(a, axis=None, dtype=None, out=None, keepdims=<no value>, *, where=<no value>)\n","Parameters:\n","\n","a: Array-like object containing numbers whose mean is desired.\n","\n","axis: Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.\n","\n","dtype: Data type to use in computing the mean. For integer inputs, the default is float64; for floating point inputs, it is the same as the input dtype.\n","\n","out: Alternate output array in which to place the result. It must have the same shape as the expected output.\n","\n","keepdims: If set to True, the axes which are reduced are left in the result as dimensions with size one.\n","\n","where: Elements to include in the mean.\n","\n","Returns:\n","\n","m: An ndarray containing the mean values.\n","\n","Examples\n","\n","Here are some examples to illustrate the usage of numpy.mean:\n","\n","import numpy as np\n","\n","# Example 1: Compute the mean of a 2D array\n","a = np.array([[1, 2], [3, 4]])\n","print(np.mean(a)) # Output: 2.5\n","\n","# Example 2: Compute the mean along the first axis (rows)\n","print(np.mean(a, axis=0)) # Output: [2. 3.]\n","\n","# Example 3: Compute the mean along the second axis (columns)\n","print(np.mean(a, axis=1)) # Output: [1.5 3.5]\n","\n","# Example 4: Compute the mean with a specified dtype\n","b = np.zeros((2, 512*512), dtype=np.float32)\n","b[0, :] = 1.0\n","b[1, :] = 0.1\n","print(np.mean(b)) # Output: 0.54999924 (inaccurate due to float32)\n","print(np.mean(b, dtype=np.float64)) # Output: 0.55000000074505806 (more accurate)\n","Important Considerations\n","\n","Precision: For floating-point input, the mean is computed using the same precision as the input. This can cause inaccuracies, especially for float32. Specifying a higher-precision accumulator using the dtype keyword can alleviate this issue\n","1\n",".\n","\n","Performance: NumPy arrays are stored in contiguous memory locations, making them faster to process compared to Python lists\n","2\n",". This is particularly beneficial in data science and scientific computing where large datasets are common\n","3\n",".\n","\n","By understanding and utilizing numpy.mean, you can efficiently compute the average values of arrays, which is a fundamental operation in many numerical and data analysis tasks."],"metadata":{"id":"fv9Z0X21RP5E"}},{"cell_type":"markdown","source":["19. How does Pandas simplify time series analysis?\n","-Pandas is a powerful library in Python that significantly simplifies time series analysis by providing intuitive and efficient tools for handling, analyzing, and visualizing time-based data. Here's how it helps:\n","\n","1. Date and Time Handling\n","Datetime Indexing: Pandas allows you to set a DatetimeIndex for your data, enabling easy slicing and filtering based on dates or time ranges.\n","Datetime Conversion: It can convert strings or other formats into datetime objects using pd.to_datetime(), making it easier to work with inconsistent date formats.\n","Date Components: You can easily extract components like year, month, day, hour, etc., using attributes like .dt.year, .dt.month, etc.\n","2. Resampling and Aggregation\n","Resampling: Pandas provides the .resample() method to aggregate data into different time frequencies (e.g., daily, monthly, yearly). For example, converting hourly data to daily averages is straightforward.\n","Rolling and Expanding Windows: With .rolling() and .expanding(), you can calculate moving averages, cumulative sums, or other window-based statistics.\n","3. Time Zone Support\n","Pandas supports time zone-aware operations, allowing you to localize timestamps to specific time zones and convert between them seamlessly.\n","4. Missing Data Handling\n","Time series often have missing data. Pandas provides methods like .fillna() and .interpolate() to handle gaps effectively.\n","5. Shifting and Lagging\n","You can use .shift() to create lagged versions of your data, which is useful for calculating changes over time or creating lagged features for modeling.\n","6. Powerful Plotting\n","Pandas integrates well with Matplotlib, enabling quick and easy visualization of time series data with .plot().\n","7. Built-in Statistical Functions\n","Pandas offers built-in methods for descriptive statistics, correlation, and other analyses, making it easier to explore time series trends and patterns.\n","Example:\n","import pandas as pd\n","\n","# Create a time series\n","date_range = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n","data = [10, 12, 15, None, 18, 20, 22, 25, 28, 30]\n","time_series = pd.Series(data, index=date_range)\n","\n","# Resample to calculate weekly mean\n","weekly_mean = time_series.resample('W').mean()\n","\n","# Fill missing values\n","time_series_filled = time_series.fillna(method='ffill')\n","\n","print(\"Original Time Series:\")\n","print(time_series)\n","print(\"\\nWeekly Mean:\")\n","print(weekly_mean)\n","print(\"\\nFilled Time Series:\")\n","print(time_series_filled)\n","\n","\n","By abstracting away much of the complexity, Pandas makes time series analysis more accessible and efficient, even for beginners."],"metadata":{"id":"iPkvWTQ_RhFi"}},{"cell_type":"markdown","source":["20. What is the role of a pivot table in Pandas?\n","-A pivot table in Pandas is a powerful tool for data analysis and summarization. It allows you to reorganize and aggregate data in a flexible way, making it easier to extract meaningful insights. Here's a concise explanation of its role:\n","\n","Role of a Pivot Table in Pandas\n","\n","Data Summarization: It helps summarize large datasets by grouping data based on one or more keys (columns) and applying aggregation functions like sum, mean, count, etc.\n","\n","Example: Summing up sales by region and product category.\n","\n","Reshaping Data: Pivot tables allow you to reshape data into a more readable or analyzable format by creating a matrix-like structure with rows and columns.\n","\n","Example: Converting long-format data into a wide-format table.\n","\n","Custom Aggregations: You can apply custom aggregation functions to calculate metrics like averages, totals, or percentages for specific groups.\n","\n","Multi-Level Indexing: Pivot tables support hierarchical indexing, enabling you to analyze data across multiple dimensions (e.g., grouping by both region and year).\n","\n","Key Features\n","pivot_table() Function: The primary function in Pandas to create pivot tables.\n","Parameters:\n","index: Defines rows of the pivot table.\n","columns: Defines columns of the pivot table.\n","values: Specifies the data to aggregate.\n","aggfunc: Defines the aggregation function (e.g., sum, mean, count).\n","Example Code\n","import pandas as pd\n","\n","# Sample dataset\n","data = {\n","    'Region': ['North', 'South', 'North', 'East', 'South'],\n","    'Product': ['A', 'B', 'A', 'C', 'B'],\n","    'Sales': [100, 200, 150, 300, 250]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Creating a pivot table\n","pivot = pd.pivot_table(df,\n","                       index='Region',\n","                       columns='Product',\n","                       values='Sales',\n","                       aggfunc='sum',\n","                       fill_value=0)\n","\n","print(pivot)\n","\n","Output\n","Product      A    B    C\n","Region                    \n","East         0    0  300\n","North      250    0    0\n","South        0  450    0\n","\n","\n","This example demonstrates how pivot tables can transform raw data into a structured summary, making it easier to analyze trends and patterns."],"metadata":{"id":"DXAyKgVeT0UY"}},{"cell_type":"markdown","source":["21. Why is NumPy’s array slicing faster than Python’s list slicing?\n","-NumPy is a fundamental package for scientific computing in Python, providing efficient operations on large arrays and matrices. It is significantly faster than Python lists for several reasons:\n","\n","Homogeneous Data and Contiguous Memory\n","\n","NumPy arrays store elements of the same data type, making them more compact and memory-efficient than lists, which can hold elements of varying data types\n","1\n",". This homogeneity allows NumPy to store elements in contiguous memory locations, reducing memory fragmentation and enabling faster access\n","2\n",".\n","\n","Vectorized Operations\n","\n","NumPy supports vectorized operations, which means that operations are applied element-wise to entire arrays without the need for explicit loops. This is achieved through broadcasting, which allows NumPy to perform operations on arrays of different shapes efficiently\n","1\n",". For example:\n","\n","import numpy as np\n","\n","# Create two NumPy arrays\n","array1 = np.arange(1000000)\n","array2 = np.arange(1000000)\n","\n","# Perform element-wise multiplication\n","resultantArray = array1 * array2\n","In contrast, performing the same operation with Python lists requires explicit loops, which are slower due to Python's interpretation overhead."],"metadata":{"id":"TjZWA6c1UJq9"}},{"cell_type":"markdown","source":["22.What are some common use cases for Seaborn?\n","-Seaborn is a powerful Python library for data visualization built on top of Matplotlib. It is widely used for creating informative and aesthetically pleasing statistical graphics. Here are some common use cases for Seaborn:\n","\n","1. Exploratory Data Analysis (EDA)\n","Visualizing distributions: Use plots like distplot, kdeplot, or histplot to understand the distribution of a single variable.\n","Comparing distributions: Use boxplot, violinplot, or stripplot to compare distributions across categories.\n","Pairwise relationships: Use pairplot or jointplot to explore relationships between multiple variables.\n","2. Correlation and Relationships\n","Heatmaps: Use heatmap to visualize correlation matrices or other tabular data.\n","Scatter plots: Use scatterplot or relplot to examine relationships between two continuous variables.\n","Regression analysis: Use regplot or lmplot to visualize linear regression and trends.\n","3. Categorical Data Visualization\n","Bar plots: Use barplot to show aggregated values (e.g., mean, median) for categories.\n","Count plots: Use countplot to display the frequency of categories.\n","Swarm and strip plots: Use swarmplot or stripplot for detailed visualization of individual data points within categories.\n","4. Time Series Analysis\n","Use lineplot to visualize trends over time, such as stock prices, weather data, or sales trends.\n","5. Customizing and Enhancing Visualizations\n","Themes: Apply built-in themes like darkgrid, whitegrid, or ticks to improve aesthetics.\n","Faceted plots: Use FacetGrid or catplot to create multi-panel plots for subgroup analysis.\n","Color palettes: Use Seaborn's color palettes (e.g., coolwarm, viridis) for visually appealing plots.\n","6. Statistical Analysis\n","Confidence intervals: Automatically include confidence intervals in plots like lineplot or barplot.\n","Distribution fitting: Use kdeplot to fit and visualize kernel density estimates.\n","\n","Seaborn simplifies complex visualizations and integrates seamlessly with Pandas, making it an essential tool for data scientists and analysts."],"metadata":{"id":"sMzOqRdBUd-v"}},{"cell_type":"markdown","source":["PRACTICAL----"],"metadata":{"id":"IihnPq1oUs4I"}},{"cell_type":"code","source":["1. How do you create a 2D NumPy array and calculate the sum of each row?\n","-import numpy as np\n","\n","# Creating a 2D NumPy array\n","arr = np.array([[1, 2, 3],\n","                [4, 5, 6],\n","                [7, 8, 9]])\n","\n","# Summing each row (axis=1)\n","row_sums = np.sum(arr, axis=1)\n","\n","print(row_sums)  # Output: [ 6 15 24 ]\n"],"metadata":{"id":"T-InPeckUxlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" 2.Write a Pandas script to find the mean of a specific column in a DataFrame?\n"," -import pandas as pd\n","\n","# Creating a sample DataFrame\n","data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n","        'Age': [25, 30, 35, 40],\n","        'Salary': [50000, 60000, 70000, 80000]}\n","\n","df = pd.DataFrame(data)\n","\n","# Finding the mean of the 'Salary' column\n","mean_salary = df['Salary'].mean()\n","\n","print(f\"Mean Salary: {mean_salary}\")\n"],"metadata":{"id":"Y4fTdodJVPDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["3. Create a scatter plot using Matplotlib?\n","-import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Generating sample data\n","x = np.random.rand(50) * 10  # Random values for X-axis\n","y = np.random.rand(50) * 10  # Random values for Y-axis\n","\n","# Creating the scatter plot\n","plt.scatter(x, y, color='blue', marker='o', alpha=0.7)\n","\n","# Adding labels and title\n","plt.xlabel(\"X Values\")\n","plt.ylabel(\"Y Values\")\n","plt.title(\"Simple Scatter Plot\")\n","\n","# Display the plot\n","plt.show()\n"],"metadata":{"id":"zLPU3VfwVwMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["4. How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n","-import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Creating a sample DataFrame\n","data = {'A': [1, 2, 3, 4, 5],\n","        'B': [2, 3, 4, 5, 6],\n","        'C': [5, 8, 7, 6, 5],\n","        'D': [10, 9, 7, 6, 4]}\n","\n","df = pd.DataFrame(data)\n","\n","# Calculating correlation matrix\n","corr_matrix = df.corr()\n","\n","# Plotting the heatmap\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n","plt.title(\"Correlation Matrix Heatmap\")\n","plt.show()\n"],"metadata":{"id":"7zI7fqexV-WV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["5. Generate a bar plot using Plotly?\n","-import plotly.graph_objects as go\n","\n","# Sample data\n","categories = ['A', 'B', 'C', 'D', 'E']\n","values = [10, 20, 15, 25, 30]\n","\n","# Creating the bar plot\n","fig = go.Figure(data=[go.Bar(x=categories, y=values, marker_color='blue')])\n","\n","# Adding title and labels\n","fig.update_layout(title=\"Simple Bar Plot with Plotly\",\n","                  xaxis_title=\"Categories\",\n","                  yaxis_title=\"Values\")\n","\n","# Display the plot\n","fig.show()\n"],"metadata":{"id":"2uCKpEAmWNS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["6. Create a DataFrame and add a new column based on an existing column?\n","-import pandas as pd\n","\n","# Creating a sample DataFrame\n","data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n","        'Salary': [50000, 60000, 70000, 80000]}\n","\n","df = pd.DataFrame(data)\n","\n","# Adding a new column 'Tax' (10% of Salary)\n","df['Tax'] = df['Salary'] * 0.1\n","\n","print(df)\n"],"metadata":{"id":"zMW-HTRJWVah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["7. Write a program to perform element-wise multiplication of two NumPy arrays?\n","-import numpy as np\n","\n","# Creating two NumPy arrays\n","array1 = np.array([1, 2, 3, 4])\n","array2 = np.array([5, 6, 7, 8])\n","\n","# Using '*' operator\n","result1 = array1 * array2\n","\n","# Using np.multiply()\n","result2 = np.multiply(array1, array2)\n","\n","print(\"Result using '*':\", result1)\n","print(\"Result using np.multiply():\", result2)\n","\n","======OUTPUT=========\n","Result using '*': [ 5 12 21 32]\n","Result using np.multiply(): [ 5 12 21 32]\n","\n"],"metadata":{"id":"S5zmrK_YWflp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["8. Create a line plot with multiple lines using Matplotlib?\n","-import matplotlib.pyplot as plt\n","\n","# Sample data\n","x = [1, 2, 3, 4, 5]\n","y1 = [2, 4, 6, 8, 10]  # First line\n","y2 = [1, 3, 5, 7, 9]   # Second line\n","y3 = [3, 6, 9, 12, 15]  # Third line\n","\n","# Plot multiple lines\n","plt.plot(x, y1, label=\"Line 1\", color=\"blue\", linestyle=\"--\", marker=\"o\")\n","plt.plot(x, y2, label=\"Line 2\", color=\"red\", linestyle=\"-.\", marker=\"s\")\n","plt.plot(x, y3, label=\"Line 3\", color=\"green\", linestyle=\":\", marker=\"^\")\n","\n","# Adding title and labels\n","plt.title(\"Multiple Line Plot Example\")\n","plt.xlabel(\"X-axis\")\n","plt.ylabel(\"Y-axis\")\n","\n","# Display legend\n","plt.legend()\n","\n","# Show the plot\n","plt.show()\n","=========OUTPUT========\n","\n","\n","\n"],"metadata":{"id":"_sRojWe6Wyrr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["9. Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold?\n","-import pandas as pd\n","\n","# Creating a sample DataFrame\n","data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n","        'Age': [25, 30, 35, 40],\n","        'Salary': [50000, 60000, 70000, 80000]}\n","\n","df = pd.DataFrame(data)\n","\n","# Filtering rows where 'Salary' is greater than 60000\n","filtered_df = df[df['Salary'] > 60000]\n","\n","print(filtered_df)\n","==========OUTPUT=========\n","     Name  Age  Salary\n","2  Charlie   35  70000\n","3   David   40  80000\n"],"metadata":{"id":"CTOtlC-9XA9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["10. Create a histogram using Seaborn to visualize a distribution?\n","-import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Generating sample data (random normal distribution)\n","data = np.random.randn(1000)  # 1000 data points with a normal distribution\n","\n","# Creating the histogram\n","plt.figure(figsize=(8, 5))\n","sns.histplot(data, bins=30, kde=True, color=\"blue\")\n","\n","# Adding labels and title\n","plt.xlabel(\"Value\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Histogram with Seaborn\")\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"id":"x0ZjhEgnYILE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["11. Perform matrix multiplication using NumPy?\n","-import numpy as np\n","\n","# Creating two matrices (2x2)\n","A = np.array([[1, 2],\n","              [3, 4]])\n","\n","B = np.array([[5, 6],\n","              [7, 8]])\n","\n","# Using '@' operator\n","result1 = A @ B\n","\n","# Using np.matmul()\n","result2 = np.matmul(A, B)\n","\n","print(\"Result using '@':\\n\", result1)\n","print(\"Result using np.matmul():\\n\", result2)\n","\n","\n","============OUTPUT=============\n","Result using '@':\n"," [[19 22]\n","  [43 50]]\n","\n","Result using np.matmul():\n"," [[19 22]\n","  [43 50]]\n"],"metadata":{"id":"RBFohfkAYSjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["12. Use Pandas to load a CSV file and display its first 5 rows?\n","-import pandas as pd\n","\n","# Loading the CSV file (ensure the path is correct)\n","df = pd.read_csv(\"your_file.csv\")\n","\n","# Displaying the first 5 rows\n","print(df.head())\n"],"metadata":{"id":"qb7hs1-qYe8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["13. Create a 3D scatter plot using Plotly.\n","-import plotly.graph_objects as go\n","import numpy as np\n","\n","# Generating sample data\n","x = np.random.rand(50) * 10\n","y = np.random.rand(50) * 10\n","z = np.random.rand(50) * 10\n","\n","# Creating the 3D scatter plot\n","fig = go.Figure(data=[go.Scatter3d(\n","    x=x, y=y, z=z,\n","    mode='markers',\n","    marker=dict(size=5, color=z, colorscale='Viridis', opacity=0.8)\n",")])\n","\n","# Adding title and labels\n","fig.update_layout(title=\"3D Scatter Plot\",\n","                  scene=dict(xaxis_title=\"X-axis\",\n","                             yaxis_title=\"Y-axis\",\n","                             zaxis_title=\"Z-axis\"))\n","\n","# Display the plot\n","fig.show()\n"],"metadata":{"id":"5vgJi-omYtrB"},"execution_count":null,"outputs":[]}]}